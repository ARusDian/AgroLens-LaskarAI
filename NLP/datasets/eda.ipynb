{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paket 'stopwords' NLTK tidak ditemukan, mencoba mengunduh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/noir/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/noir/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paket 'stopwords' berhasil diunduh.\n",
      "Paket 'punkt' NLTK tidak ditemukan, mencoba mengunduh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paket 'punkt' berhasil diunduh.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Unduh Paket NLTK yang Diperlukan ---\n",
    "# Cara ini lebih langsung dan akan mencoba mengunduh jika belum ada.\n",
    "try:\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError: # Tangkap LookupError secara spesifik\n",
    "    print(\"Paket 'stopwords' NLTK tidak ditemukan, mencoba mengunduh...\")\n",
    "    nltk.download('stopwords')\n",
    "    print(\"Paket 'stopwords' berhasil diunduh.\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError: # Tangkap LookupError secara spesifik\n",
    "    print(\"Paket 'punkt' NLTK tidak ditemukan, mencoba mengunduh...\")\n",
    "    nltk.download('punkt')\n",
    "    print(\"Paket 'punkt' berhasil diunduh.\")\n",
    "\n",
    "# Setelah memastikan paket diunduh, baru impor bagian spesifiknya\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# --- (Sisa kode Anda untuk memuat data, inferensi, visualisasi, dll.) ---\n",
    "# Contoh:\n",
    "# file_path = Path(\"dataset.jsonl\")\n",
    "# data = []\n",
    "# ... dan seterusnya ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6a65431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencoba membaca file dari path: /mnt/d/project/7. Capstone Project Rice Leaf Disease/AgroLens-LaskarAI/datasets/dataset.jsonl\n",
      "Error: File 'datasets/dataset.jsonl' tidak ditemukan atau bukan file.\n",
      "Pastikan path dan nama file sudah benar dan file tersebut ada di lokasi yang ditentukan.\n",
      "\n",
      "DataFrame kosong karena terjadi error atau file tidak ditemukan/kosong.\n"
     ]
    }
   ],
   "source": [
    "# 1. Tentukan path yang BENAR ke file dataset.jsonl Anda\n",
    "# Jika notebook/skrip Anda ada di folder 'NLP' dan file ada di 'NLP/datasets/dataset.jsonl':\n",
    "nama_direktori_dataset = \"datasets\" \n",
    "nama_file_asli = \"dataset.jsonl\"\n",
    "file_path = Path(nama_direktori_dataset) / nama_file_asli # Menjadi \"datasets/dataset.jsonl\"\n",
    "\n",
    "# Atau jika file ada di direktori yang sama dengan skrip (jarang terjadi jika ada folder 'datasets'):\n",
    "# file_path = Path(\"dataset.jsonl\") \n",
    "\n",
    "print(f\"Mencoba membaca file dari path: {file_path.resolve()}\") # Mencetak path absolut untuk verifikasi\n",
    "\n",
    "try:\n",
    "    # 2. Periksa apakah file ada SEBELUM memanggil read_json\n",
    "    if file_path.exists() and file_path.is_file():\n",
    "        # 3. Baca file JSONL langsung ke DataFrame pandas\n",
    "        df = pd.read_json(file_path, lines=True, encoding='utf-8')\n",
    "        \n",
    "        print(\"\\nDataFrame berhasil dibaca dari file JSONL:\")\n",
    "        print(df.head()) # Tampilkan beberapa baris pertama\n",
    "        print(f\"\\nJumlah total data: {len(df)}\")\n",
    "        # df.info() # Untuk melihat info lebih detail\n",
    "    else:\n",
    "        print(f\"Error: File '{file_path}' tidak ditemukan atau bukan file.\")\n",
    "        print(\"Pastikan path dan nama file sudah benar dan file tersebut ada di lokasi yang ditentukan.\")\n",
    "        df = pd.DataFrame() # Buat DataFrame kosong jika file tidak ada agar kode selanjutnya tidak error\n",
    "\n",
    "except ValueError as e: # Ini akan menangkap error jika JSON per baris tidak valid\n",
    "    print(f\"Error saat mem-parsing data JSON dalam file: {e}\")\n",
    "    print(\"Pastikan setiap baris dalam file adalah objek JSON yang valid.\")\n",
    "    df = pd.DataFrame() # Buat DataFrame kosong\n",
    "except Exception as e: # Menangkap error lain yang mungkin terjadi\n",
    "    print(f\"Terjadi error yang tidak terduga: {e}\")\n",
    "    df = pd.DataFrame() # Buat DataFrame kosong\n",
    "\n",
    "# Anda bisa melanjutkan dengan df di sini, periksa apakah df kosong jika terjadi error\n",
    "if df.empty:\n",
    "    print(\"\\nDataFrame kosong karena terjadi error atau file tidak ditemukan/kosong.\")\n",
    "else:\n",
    "    print(\"\\nAnalisis bisa dilanjutkan dengan DataFrame di atas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b647c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
