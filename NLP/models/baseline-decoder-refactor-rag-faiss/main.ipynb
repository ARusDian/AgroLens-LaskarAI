{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a99c492",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2fdc6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "✅ Tokenizer saved to tokenizer-agrolens.json\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers, decoders\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "import json\n",
    "dataset_path = \"../../datasets/dataset.jsonl\"\n",
    "\n",
    "# === Load data ===\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = []\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        texts.append(data[\"prompt\"])\n",
    "        texts.append(data[\"response\"])\n",
    "\n",
    "# === Write to plain text (required by tokenizer trainer) ===\n",
    "with open(\"tokenizer_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for text in texts:\n",
    "        f.write(text.strip() + \"\\n\")\n",
    "\n",
    "# === Init tokenizer ===\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=8000,\n",
    "    show_progress=True,\n",
    "    special_tokens=[\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"],\n",
    ")\n",
    "\n",
    "# === Train ===\n",
    "tokenizer.train([\"tokenizer_corpus.txt\"], trainer)\n",
    "\n",
    "# === Post-processing untuk auto menambahkan <s> dan </s> saat encoding\n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"<s> $A </s>\",\n",
    "    pair=\"<s> $A </s> <s> $B </s>\",\n",
    "    special_tokens=[\n",
    "        (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "        (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    ],\n",
    ")\n",
    "\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "# === Save ===\n",
    "tokenizer.save(\"tokenizer-agrolens.json\")   \n",
    "print(\"✅ Tokenizer saved to tokenizer-agrolens.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d359a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'ĠApa', 'Ġitu', 'Ġpenyakit', 'Ġblast', '?', '</s>']\n",
      "[1, 176, 289, 128, 260, 21, 2]\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer-agrolens.json\")\n",
    "enc = tokenizer.encode(\"Apa itu penyakit blast?\")\n",
    "print(enc.tokens)\n",
    "print(enc.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc0844",
   "metadata": {},
   "source": [
    "# GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "645b29c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class DecoderBlock(layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=n_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(d_model * 4, activation='relu'),\n",
    "            layers.Dense(d_model),\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        attn = self.mha(x, x, attention_mask=mask, use_causal_mask=True)\n",
    "        attn = self.dropout1(attn, training=training)\n",
    "        x = self.norm1(x + attn)\n",
    "\n",
    "        ffn_out = self.ffn(x)\n",
    "        ffn_out = self.dropout2(ffn_out, training=training)\n",
    "        return self.norm2(x + ffn_out)\n",
    "\n",
    "\n",
    "class AgroLensGPT(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        max_length=512,\n",
    "        d_model=256,\n",
    "        n_heads=4,\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.token_embed = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = layers.Embedding(max_length, d_model)\n",
    "        self.blocks = [DecoderBlock(d_model, n_heads, dropout) for _ in range(n_layers)]\n",
    "        self.final_norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.output_head = layers.Dense(vocab_size)\n",
    "\n",
    "        # Precomputed causal mask (for max_length)\n",
    "        self.causal_mask = tf.linalg.band_part(tf.ones((max_length, max_length)), -1, 0)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        B, T = tf.shape(x)[0], tf.shape(x)[1]\n",
    "        token_emb = self.token_embed(x)  # (B, T, d_model)\n",
    "        pos_indices = tf.range(start=0, limit=T)\n",
    "        pos_emb = self.pos_embed(pos_indices)[tf.newaxis, :, :]  # (1, T, d_model)\n",
    "\n",
    "        h = token_emb + pos_emb  # (B, T, d_model)\n",
    "        mask = self.causal_mask[:T, :T][tf.newaxis, tf.newaxis, :, :]  # (1, 1, T, T)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            h = block(h, training=training, mask=mask)\n",
    "\n",
    "        h = self.final_norm(h)\n",
    "        return self.output_head(h)  # (B, T, vocab_size)\n",
    "\n",
    "    def generate(self, tokenizer, prompt, max_new_tokens=50):\n",
    "        input_ids = tokenizer.encode(prompt).ids\n",
    "        input_tensor = tf.constant([input_ids], dtype=tf.int32)\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(input_tensor, training=False)\n",
    "            next_token = tf.argmax(logits[:, -1, :], axis=-1, output_type=tf.int32)\n",
    "            input_tensor = tf.concat(\n",
    "                [input_tensor, tf.expand_dims(next_token, axis=1)], axis=1\n",
    "            )\n",
    "\n",
    "            if next_token.numpy()[0] == tokenizer.token_to_id(\"</s>\"):\n",
    "                break\n",
    "            if input_tensor.shape[1] >= self.max_length:\n",
    "                break\n",
    "\n",
    "        return tokenizer.decode(input_tensor[0].numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7fec44d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"agro_lens_gpt_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"agro_lens_gpt_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_26          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_8 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_9 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_10 (\u001b[38;5;33mDecoderBlock\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_11 (\u001b[38;5;33mDecoderBlock\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_26          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64, 8000)\n"
     ]
    }
   ],
   "source": [
    "model = AgroLensGPT(vocab_size=8000)\n",
    "display(model.summary())\n",
    "sample_input = tf.random.uniform((2, 64), minval=0, maxval=8000, dtype=tf.int32)\n",
    "logits = model(sample_input)\n",
    "print(logits.shape)  # Expected: (2, 64, 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ad101",
   "metadata": {},
   "source": [
    "# Loader dan Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71d0427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "\n",
    "class AgroDatasetTF(tf.data.Dataset):\n",
    "    def __new__(cls, path, tokenizer_path, max_len=256):\n",
    "        tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "        samples = []\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                prompt = data[\"prompt\"]\n",
    "                response = data[\"response\"]\n",
    "                combined = f\"{prompt} {response}\"\n",
    "\n",
    "                # Tokenize and truncate\n",
    "                ids = tokenizer.encode(combined).ids[:max_len]\n",
    "\n",
    "                if len(ids) >= 2:  # minimal length to create input/label\n",
    "                    input_ids = ids[:-1]\n",
    "                    labels = ids[1:]\n",
    "                    samples.append((input_ids, labels))\n",
    "\n",
    "        # Convert to TensorFlow tensors\n",
    "        def gen():\n",
    "            for input_ids, labels in samples:\n",
    "                yield {\n",
    "                    \"input_ids\": tf.constant(input_ids, dtype=tf.int32),\n",
    "                    \"labels\": tf.constant(labels, dtype=tf.int32),\n",
    "                }\n",
    "\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_signature={\n",
    "                \"input_ids\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "                \"labels\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fe55cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 40) (8, 40)\n"
     ]
    }
   ],
   "source": [
    "dataset = AgroDatasetTF(\n",
    "    dataset_path, \"tokenizer-agrolens.json\", max_len=512\n",
    ")\n",
    "dataset = dataset.padded_batch(8, padded_shapes={\"input_ids\": [None], \"labels\": [None]})\n",
    "for batch in dataset.take(1):\n",
    "    print(batch[\"input_ids\"].shape, batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d8618d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"agro_lens_gpt_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"agro_lens_gpt_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_35          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_7 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_12 (\u001b[38;5;33mDecoderBlock\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_13 (\u001b[38;5;33mDecoderBlock\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_14 (\u001b[38;5;33mDecoderBlock\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_15 (\u001b[38;5;33mDecoderBlock\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_35          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 50\u001b[0m\n\u001b[1;32m     48\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     49\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 50\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     52\u001b[0m steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:906\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 906\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    910\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m    911\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[1;32m    912\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/py310/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LR = 3e-4\n",
    "MAX_LEN = 512\n",
    "\n",
    "# --- Dataset ---\n",
    "dataset = AgroDatasetTF(\n",
    "    dataset_path, \"tokenizer-agrolens.json\", max_len=MAX_LEN\n",
    ")\n",
    "dataset = dataset.padded_batch(\n",
    "    BATCH_SIZE, padded_shapes={\"input_ids\": [None], \"labels\": [None]}\n",
    ")\n",
    "dataset = dataset.shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# --- Model ---\n",
    "model = AgroLensGPT(vocab_size=8000)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction=\"none\"\n",
    ")\n",
    "\n",
    "display(model.summary())\n",
    "\n",
    "# --- Custom Training Loop ---\n",
    "@tf.function\n",
    "def train_step(input_ids, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(input_ids, training=True)\n",
    "        # Shifted label loss, ignoring padding (-100 equivalent in PyTorch)\n",
    "        mask = tf.cast(labels != -100, tf.float32)\n",
    "        loss_values = loss_fn(labels, logits)\n",
    "        loss = tf.reduce_sum(loss_values * mask) / tf.reduce_sum(mask)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss = train_step(input_ids, labels)\n",
    "        total_loss += loss.numpy()\n",
    "        steps += 1\n",
    "\n",
    "    avg_loss = total_loss / steps\n",
    "    print(f\"📘 Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "\n",
    "# --- Save weights ---\n",
    "model.save_weights(\"agrolens_model_tf.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "721b5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class AgroTransformerEncoder(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, vocab_size=8000, max_length=128, d_model=256, n_heads=4, dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.token_embed = layers.Embedding(input_dim=vocab_size, output_dim=d_model)\n",
    "        self.pos_embed = layers.Embedding(input_dim=max_length, output_dim=d_model)\n",
    "\n",
    "        self.attn = layers.MultiHeadAttention(num_heads=n_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(d_model * 4, activation=\"relu\"),\n",
    "                layers.Dropout(dropout),\n",
    "                layers.Dense(d_model),\n",
    "            ]\n",
    "        )\n",
    "        self.dropout = layers.Dropout(dropout)\n",
    "        self.ln1 = layers.LayerNormalization()\n",
    "        self.ln2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        pos = tf.range(start=0, limit=seq_len, delta=1)\n",
    "        pos = tf.expand_dims(pos, 0)\n",
    "        x = self.token_embed(x) + self.pos_embed(pos)\n",
    "\n",
    "        attn_output = self.attn(x, x, attention_mask=None, use_causal_mask=False)\n",
    "        x = self.ln1(x + self.dropout(attn_output, training=training))\n",
    "\n",
    "        ffn_output = self.ffn(x, training=training)\n",
    "        x = self.ln2(x + self.dropout(ffn_output, training=training))\n",
    "\n",
    "        x = tf.reduce_mean(x, axis=1)  # Global average pooling\n",
    "        return x  # shape: (batch, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d28847bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# --- Konstanta dan Load Model ---\n",
    "MODEL_PATH = \"agrolens_model_tf.weights.h5\"\n",
    "TOKENIZER_PATH = \"tokenizer-agrolens.json\"\n",
    "VOCAB_SIZE = 8000\n",
    "MAX_LEN = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f88d56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌾 AgroLens Menjawab:\n",
      " Apa itu penyakit blast? padi dapat terserang Bacterial Blight pada padi disebabkan oleh bakteri patogen Xanthomonas oryzae pv. oryzae.\n"
     ]
    }
   ],
   "source": [
    "def generate(prompt: str, max_new_tokens: int = 50) -> str:\n",
    "    \"\"\"\n",
    "    Generate teks dari model AgroLensGPT berbasis prompt dan tokenizer.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Prompt input dari user.\n",
    "        max_new_tokens (int): Jumlah maksimum token baru yang dihasilkan.\n",
    "\n",
    "    Returns:\n",
    "        str: Hasil teks yang dihasilkan oleh model.\n",
    "    \"\"\"\n",
    "    # Tokenisasi prompt dan potong jika terlalu panjang\n",
    "    input_ids = tokenizer.encode(prompt).ids[:MAX_LEN]\n",
    "    input_tensor = tf.constant([input_ids], dtype=tf.int32)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Prediksi logit dari model\n",
    "        logits = model(input_tensor, training=False)\n",
    "\n",
    "        # Ambil token berikutnya (greedy decoding)\n",
    "        next_token = tf.argmax(logits[:, -1, :], axis=-1, output_type=tf.int32)\n",
    "\n",
    "        # Gabungkan token ke input\n",
    "        input_tensor = tf.concat(\n",
    "            [input_tensor, tf.expand_dims(next_token, axis=1)], axis=1\n",
    "        )\n",
    "\n",
    "        # Stop jika token </s> ditemukan\n",
    "        if next_token.numpy()[0] == tokenizer.token_to_id(\"</s>\"):\n",
    "            break\n",
    "\n",
    "        # Stop jika melebihi panjang maksimum\n",
    "        if input_tensor.shape[1] >= MAX_LEN:\n",
    "            break\n",
    "\n",
    "    # Decode seluruh output menjadi teks\n",
    "    output_ids = input_tensor[0].numpy().tolist()\n",
    "    return tokenizer.decode(output_ids)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"Apa itu penyakit blast?\"\n",
    "    print(\"🌾 AgroLens Menjawab:\")\n",
    "    print(generate(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "140283c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruvne/anaconda3/envs/py310/lib/python3.10/site-packages/keras/src/layers/layer.py:391: UserWarning: `build()` was called on layer 'agro_transformer_encoder_5', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌾 AgroLens Menjawab:\n",
      " \n",
      "- Bakteri Xoo mengeluarkan beberapa protein (seperti selulase, lipase, xilanase) yang bisa merusak dinding sel padi. Selain itu, bakteri ini juga mengeluarkan 'efektor' lain (seperti XopN, XopQ, XopX, XopZ) yang berfungsi untuk menekan atau mematikan sistem kekebalan alami tanaman padi.\n",
      "- Gejala khas tanaman padi yang terinfeksi tungro meliputi kerdil, daun yang menguning sampai berwarna kuning-oranye, pertumbuhan anakan yang rendah, malai sterilisasi, dan bercak coklat gelap yang tidak beraturan pada daun. Daun muda tampak seperti memiliki bercak berwarna-warni atau klorosis antar tulang daun.\n",
      "- Penting sekali untuk terus mengawasi bakteri Xoo karena bakteri ini pintar berubah-ubah dan tanaman\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "# --- Load FAISS index ---\n",
    "index = faiss.read_index(\"kb_faiss.index\")\n",
    "with open(\"kb_ids.json\", \"r\") as f:\n",
    "    id_map = json.load(f)\n",
    "\n",
    "# --- Load KB full texts ---\n",
    "with open(\"kb.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    kb_data = {json.loads(l)[\"id\"]: json.loads(l)[\"text\"] for l in f}\n",
    "\n",
    "# --- Load Tokenizer ---\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer-agrolens.json\")\n",
    "\n",
    "# --- Load Encoder ---\n",
    "encoder = AgroTransformerEncoder()\n",
    "encoder.build(input_shape=(None, 128))\n",
    "\n",
    "# --- Load Decoder Model ---\n",
    "gpt = AgroLensGPT(vocab_size=8000)\n",
    "gpt = AgroLensGPT(vocab_size=VOCAB_SIZE)\n",
    "dummy_input = tf.constant([[1] * 64], dtype=tf.int32)  # bentuk (1, 64)\n",
    "_ = gpt(dummy_input)  # memanggil forward p\n",
    "gpt.load_weights(\"agrolens_model_tf.weights.h5\")\n",
    "\n",
    "\n",
    "# --- Generate function ---\n",
    "def rag_generate(prompt: str, top_k=3, max_tokens=50, max_input_len=128):\n",
    "    # Step 1: Embed pertanyaan dengan encoder\n",
    "    input_ids = tokenizer.encode(prompt).ids[:max_input_len]\n",
    "    input_tensor = tf.constant([input_ids + [0] * (max_input_len - len(input_ids))])\n",
    "    query_vec = encoder(input_tensor, training=False).numpy()\n",
    "\n",
    "    # Step 2: Retrieve top-K konteks dari FAISS\n",
    "    D, I = index.search(query_vec, top_k)\n",
    "    retrieved_texts = [kb_data[id_map[i]] for i in I[0]]\n",
    "\n",
    "    # Step 3: Gabungkan konteks + pertanyaan\n",
    "    context = \"\\n- \" + \"\\n- \".join(retrieved_texts)\n",
    "    full_input = f\"{context}\\n\\nPertanyaan: {prompt}\\nJawaban:\"\n",
    "    full_ids = tokenizer.encode(full_input).ids[:max_input_len]\n",
    "    decoder_input = tf.constant(\n",
    "        [full_ids + [0] * (max_input_len - len(full_ids))], dtype=tf.int32\n",
    "    )\n",
    "\n",
    "    # Step 4: Generate token demi token\n",
    "    END_TOKEN_ID = tokenizer.token_to_id(\"</s>\")\n",
    "    for _ in range(max_tokens):\n",
    "        logits = gpt(decoder_input, training=False)\n",
    "        next_token = tf.expand_dims(\n",
    "            tf.cast(tf.argmax(logits[:, -1, :], axis=-1), tf.int32), 1\n",
    "        )\n",
    "        decoder_input = tf.concat([decoder_input, next_token], axis=1)\n",
    "\n",
    "        if decoder_input.shape[1] >= 128 or next_token.numpy()[0] == END_TOKEN_ID:\n",
    "            break\n",
    "\n",
    "    output_ids = decoder_input[0].numpy().tolist()\n",
    "    clean_ids = [i for i in output_ids if i != tokenizer.token_to_id(\"<pad>\")]\n",
    "    return tokenizer.decode(clean_ids)\n",
    "\n",
    "\n",
    "# --- Example usage ---\n",
    "if __name__ == \"__main__\":\n",
    "    question = \"Apa itu penyakit blast?\"\n",
    "    print(\"🌾 AgroLens Menjawab:\")\n",
    "    print(rag_generate(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53524a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c94131218b4dd8a6a5c7dc1859a586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='Apa itu penyakit blast?', description='❓ Pertanyaan:', layout=Layout(width='100%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "input_box = widgets.Text(\n",
    "    value=\"Apa itu penyakit blast?\",\n",
    "    placeholder=\"Tulis pertanyaan di sini...\",\n",
    "    description=\"❓ Pertanyaan:\",\n",
    "    layout=widgets.Layout(width=\"100%\"),\n",
    ")\n",
    "\n",
    "output_box = widgets.Output()\n",
    "generate_button = widgets.Button(\n",
    "    description=\"Jawab 🚀\", button_style=\"success\", layout=widgets.Layout(width=\"15%\")\n",
    ")\n",
    "\n",
    "\n",
    "def on_generate_clicked(b):\n",
    "    prompt = input_box.value\n",
    "    response = rag_generate(prompt)\n",
    "    output_box.clear_output()\n",
    "    with output_box:\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"### 🧑 Kamu: \\n{prompt}\\n---\\n### 🌾 AgroLens Menjawab:\\n{response}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "generate_button.on_click(on_generate_clicked)\n",
    "\n",
    "# Tampilkan\n",
    "display(widgets.VBox([input_box, generate_button, output_box]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
