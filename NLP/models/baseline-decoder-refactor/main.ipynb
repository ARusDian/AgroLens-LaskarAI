{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a99c492",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fdc6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "âœ… Tokenizer saved to tokenizer-agrolens.json\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers, decoders\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "import json\n",
    "\n",
    "# === Load data ===\n",
    "with open(\"dataset.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = []\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        texts.append(data[\"prompt\"])\n",
    "        texts.append(data[\"response\"])\n",
    "\n",
    "# === Write to plain text (required by tokenizer trainer) ===\n",
    "with open(\"tokenizer_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for text in texts:\n",
    "        f.write(text.strip() + \"\\n\")\n",
    "\n",
    "# === Init tokenizer ===\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=8000,\n",
    "    show_progress=True,\n",
    "    special_tokens=[\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"],\n",
    ")\n",
    "\n",
    "# === Train ===\n",
    "tokenizer.train([\"tokenizer_corpus.txt\"], trainer)\n",
    "\n",
    "# === Post-processing untuk auto menambahkan <s> dan </s> saat encoding\n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"<s> $A </s>\",\n",
    "    pair=\"<s> $A </s> <s> $B </s>\",\n",
    "    special_tokens=[\n",
    "        (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "        (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    ],\n",
    ")\n",
    "\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "# === Save ===\n",
    "tokenizer.save(\"tokenizer-agrolens.json\")   \n",
    "print(\"âœ… Tokenizer saved to tokenizer-agrolens.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d359a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Ä Apa', 'Ä itu', 'Ä penyakit', 'Ä blast', '?', '</s>']\n",
      "[1, 122, 1141, 106, 149, 17, 2]\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer-agrolens.json\")\n",
    "enc = tokenizer.encode(\"Apa itu penyakit blast?\")\n",
    "print(enc.tokens)\n",
    "print(enc.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc0844",
   "metadata": {},
   "source": [
    "# GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "645b29c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:33:56.263656: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-05 00:33:56.272482: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749054836.286414    4596 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749054836.290092    4596 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749054836.299147    4596 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749054836.299166    4596 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749054836.299166    4596 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749054836.299167    4596 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-05 00:33:56.302854: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class DecoderBlock(layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=n_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(d_model * 4, activation='relu'),\n",
    "            layers.Dense(d_model),\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        attn = self.mha(x, x, attention_mask=mask, use_causal_mask=True)\n",
    "        attn = self.dropout1(attn, training=training)\n",
    "        x = self.norm1(x + attn)\n",
    "\n",
    "        ffn_out = self.ffn(x)\n",
    "        ffn_out = self.dropout2(ffn_out, training=training)\n",
    "        return self.norm2(x + ffn_out)\n",
    "\n",
    "\n",
    "class AgroLensGPT(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        max_length=512,\n",
    "        d_model=256,\n",
    "        n_heads=4,\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.token_embed = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = layers.Embedding(max_length, d_model)\n",
    "        self.blocks = [DecoderBlock(d_model, n_heads, dropout) for _ in range(n_layers)]\n",
    "        self.final_norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.output_head = layers.Dense(vocab_size)\n",
    "\n",
    "        # Precomputed causal mask (for max_length)\n",
    "        self.causal_mask = tf.linalg.band_part(tf.ones((max_length, max_length)), -1, 0)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        B, T = tf.shape(x)[0], tf.shape(x)[1]\n",
    "        token_emb = self.token_embed(x)  # (B, T, d_model)\n",
    "        pos_indices = tf.range(start=0, limit=T)\n",
    "        pos_emb = self.pos_embed(pos_indices)[tf.newaxis, :, :]  # (1, T, d_model)\n",
    "\n",
    "        h = token_emb + pos_emb  # (B, T, d_model)\n",
    "        mask = self.causal_mask[:T, :T][tf.newaxis, tf.newaxis, :, :]  # (1, 1, T, T)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            h = block(h, training=training, mask=mask)\n",
    "\n",
    "        h = self.final_norm(h)\n",
    "        return self.output_head(h)  # (B, T, vocab_size)\n",
    "\n",
    "    def generate(self, tokenizer, prompt, max_new_tokens=50):\n",
    "        input_ids = tokenizer.encode(prompt).ids\n",
    "        input_tensor = tf.constant([input_ids], dtype=tf.int32)\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(input_tensor, training=False)\n",
    "            next_token = tf.argmax(logits[:, -1, :], axis=-1, output_type=tf.int32)\n",
    "            input_tensor = tf.concat(\n",
    "                [input_tensor, tf.expand_dims(next_token, axis=1)], axis=1\n",
    "            )\n",
    "\n",
    "            if next_token.numpy()[0] == tokenizer.token_to_id(\"</s>\"):\n",
    "                break\n",
    "            if input_tensor.shape[1] >= self.max_length:\n",
    "                break\n",
    "\n",
    "        return tokenizer.decode(input_tensor[0].numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fec44d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749054839.486254    4596 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"agro_lens_gpt\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"agro_lens_gpt\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)    â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_8           â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block (\u001b[38;5;33mDecoderBlock\u001b[0m)    â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_1 (\u001b[38;5;33mDecoderBlock\u001b[0m)  â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_2 (\u001b[38;5;33mDecoderBlock\u001b[0m)  â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ decoder_block_3 (\u001b[38;5;33mDecoderBlock\u001b[0m)  â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ layer_normalization_8           â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”‚ (\u001b[38;5;33mLayerNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64, 8000)\n"
     ]
    }
   ],
   "source": [
    "model = AgroLensGPT(vocab_size=8000)\n",
    "display(model.summary())\n",
    "sample_input = tf.random.uniform((2, 64), minval=0, maxval=8000, dtype=tf.int32)\n",
    "logits = model(sample_input)\n",
    "print(logits.shape)  # Expected: (2, 64, 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ad101",
   "metadata": {},
   "source": [
    "# Loader dan Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71d0427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "\n",
    "class AgroDatasetTF(tf.data.Dataset):\n",
    "    def __new__(cls, path, tokenizer_path, max_len=256):\n",
    "        tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "        samples = []\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                prompt = data[\"prompt\"]\n",
    "                response = data[\"response\"]\n",
    "                combined = f\"{prompt} {response}\"\n",
    "\n",
    "                # Tokenize and truncate\n",
    "                ids = tokenizer.encode(combined).ids[:max_len]\n",
    "\n",
    "                if len(ids) >= 2:  # minimal length to create input/label\n",
    "                    input_ids = ids[:-1]\n",
    "                    labels = ids[1:]\n",
    "                    samples.append((input_ids, labels))\n",
    "\n",
    "        # Convert to TensorFlow tensors\n",
    "        def gen():\n",
    "            for input_ids, labels in samples:\n",
    "                yield {\n",
    "                    \"input_ids\": tf.constant(input_ids, dtype=tf.int32),\n",
    "                    \"labels\": tf.constant(labels, dtype=tf.int32),\n",
    "                }\n",
    "\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_signature={\n",
    "                \"input_ids\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "                \"labels\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fe55cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 40) (8, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:34:01.902681: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "dataset = AgroDatasetTF(\n",
    "    \"dataset.jsonl\", \"tokenizer-agrolens.json\", max_len=512\n",
    ")\n",
    "dataset = dataset.padded_batch(8, padded_shapes={\"input_ids\": [None], \"labels\": [None]})\n",
    "for batch in dataset.take(1):\n",
    "    print(batch[\"input_ids\"].shape, batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d8618d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:34:11.571322: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 1: Loss = 8.4249\n",
      "ğŸ“˜ Epoch 2: Loss = 7.5612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:34:11.846422: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 3: Loss = 7.1810\n",
      "ğŸ“˜ Epoch 4: Loss = 6.8054\n",
      "ğŸ“˜ Epoch 5: Loss = 6.4692\n",
      "ğŸ“˜ Epoch 6: Loss = 6.1275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:34:12.328888: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 7: Loss = 5.8108\n",
      "ğŸ“˜ Epoch 8: Loss = 5.5000\n",
      "ğŸ“˜ Epoch 9: Loss = 5.2042\n",
      "ğŸ“˜ Epoch 10: Loss = 4.9249\n",
      "ğŸ“˜ Epoch 11: Loss = 4.6670\n",
      "ğŸ“˜ Epoch 12: Loss = 4.4246\n",
      "ğŸ“˜ Epoch 13: Loss = 4.2080\n",
      "ğŸ“˜ Epoch 14: Loss = 4.0041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:34:13.256790: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 15: Loss = 3.8177\n",
      "ğŸ“˜ Epoch 16: Loss = 3.6471\n",
      "ğŸ“˜ Epoch 17: Loss = 3.4913\n",
      "ğŸ“˜ Epoch 18: Loss = 3.3393\n",
      "ğŸ“˜ Epoch 19: Loss = 3.2057\n",
      "ğŸ“˜ Epoch 20: Loss = 3.0742\n",
      "ğŸ“˜ Epoch 21: Loss = 2.9520\n",
      "ğŸ“˜ Epoch 22: Loss = 2.8338\n",
      "ğŸ“˜ Epoch 23: Loss = 2.7239\n",
      "ğŸ“˜ Epoch 24: Loss = 2.6218\n",
      "ğŸ“˜ Epoch 25: Loss = 2.5078\n",
      "ğŸ“˜ Epoch 26: Loss = 2.4080\n",
      "ğŸ“˜ Epoch 27: Loss = 2.3069\n",
      "ğŸ“˜ Epoch 28: Loss = 2.2186\n",
      "ğŸ“˜ Epoch 29: Loss = 2.1288\n",
      "ğŸ“˜ Epoch 30: Loss = 2.0428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:34:15.339979: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 31: Loss = 1.9561\n",
      "ğŸ“˜ Epoch 32: Loss = 1.8696\n",
      "ğŸ“˜ Epoch 33: Loss = 1.7853\n",
      "ğŸ“˜ Epoch 34: Loss = 1.7043\n",
      "ğŸ“˜ Epoch 35: Loss = 1.6210\n",
      "ğŸ“˜ Epoch 36: Loss = 1.5507\n",
      "ğŸ“˜ Epoch 37: Loss = 1.4794\n",
      "ğŸ“˜ Epoch 38: Loss = 1.4075\n",
      "ğŸ“˜ Epoch 39: Loss = 1.3424\n",
      "ğŸ“˜ Epoch 40: Loss = 1.2769\n",
      "ğŸ“˜ Epoch 41: Loss = 1.2111\n",
      "ğŸ“˜ Epoch 42: Loss = 1.1488\n",
      "ğŸ“˜ Epoch 43: Loss = 1.0928\n",
      "ğŸ“˜ Epoch 44: Loss = 1.0371\n",
      "ğŸ“˜ Epoch 45: Loss = 0.9877\n",
      "ğŸ“˜ Epoch 46: Loss = 0.9358\n",
      "ğŸ“˜ Epoch 47: Loss = 0.9053\n",
      "ğŸ“˜ Epoch 48: Loss = 0.8509\n",
      "ğŸ“˜ Epoch 49: Loss = 0.7989\n",
      "ğŸ“˜ Epoch 50: Loss = 0.7616\n",
      "ğŸ“˜ Epoch 51: Loss = 0.7146\n",
      "ğŸ“˜ Epoch 52: Loss = 0.6776\n",
      "ğŸ“˜ Epoch 53: Loss = 0.6426\n",
      "ğŸ“˜ Epoch 54: Loss = 0.6050\n",
      "ğŸ“˜ Epoch 55: Loss = 0.5747\n",
      "ğŸ“˜ Epoch 56: Loss = 0.5463\n",
      "ğŸ“˜ Epoch 57: Loss = 0.5155\n",
      "ğŸ“˜ Epoch 58: Loss = 0.4885\n",
      "ğŸ“˜ Epoch 59: Loss = 0.4656\n",
      "ğŸ“˜ Epoch 60: Loss = 0.4407\n",
      "ğŸ“˜ Epoch 61: Loss = 0.4186\n",
      "ğŸ“˜ Epoch 62: Loss = 0.3990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 00:34:19.483941: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“˜ Epoch 63: Loss = 0.3793\n",
      "ğŸ“˜ Epoch 64: Loss = 0.3613\n",
      "ğŸ“˜ Epoch 65: Loss = 0.3444\n",
      "ğŸ“˜ Epoch 66: Loss = 0.3296\n",
      "ğŸ“˜ Epoch 67: Loss = 0.3130\n",
      "ğŸ“˜ Epoch 68: Loss = 0.3024\n",
      "ğŸ“˜ Epoch 69: Loss = 0.2898\n",
      "ğŸ“˜ Epoch 70: Loss = 0.2778\n",
      "ğŸ“˜ Epoch 71: Loss = 0.2662\n",
      "ğŸ“˜ Epoch 72: Loss = 0.2556\n",
      "ğŸ“˜ Epoch 73: Loss = 0.2466\n",
      "ğŸ“˜ Epoch 74: Loss = 0.2388\n",
      "ğŸ“˜ Epoch 75: Loss = 0.2295\n",
      "ğŸ“˜ Epoch 76: Loss = 0.2234\n",
      "ğŸ“˜ Epoch 77: Loss = 0.2164\n",
      "ğŸ“˜ Epoch 78: Loss = 0.2090\n",
      "ğŸ“˜ Epoch 79: Loss = 0.2038\n",
      "ğŸ“˜ Epoch 80: Loss = 0.1978\n",
      "ğŸ“˜ Epoch 81: Loss = 0.1913\n",
      "ğŸ“˜ Epoch 82: Loss = 0.1866\n",
      "ğŸ“˜ Epoch 83: Loss = 0.1815\n",
      "ğŸ“˜ Epoch 84: Loss = 0.1796\n",
      "ğŸ“˜ Epoch 85: Loss = 0.1755\n",
      "ğŸ“˜ Epoch 86: Loss = 0.1714\n",
      "ğŸ“˜ Epoch 87: Loss = 0.1666\n",
      "ğŸ“˜ Epoch 88: Loss = 0.1642\n",
      "ğŸ“˜ Epoch 89: Loss = 0.1613\n",
      "ğŸ“˜ Epoch 90: Loss = 0.1578\n",
      "ğŸ“˜ Epoch 91: Loss = 0.1552\n",
      "ğŸ“˜ Epoch 92: Loss = 0.1525\n",
      "ğŸ“˜ Epoch 93: Loss = 0.1504\n",
      "ğŸ“˜ Epoch 94: Loss = 0.1486\n",
      "ğŸ“˜ Epoch 95: Loss = 0.1468\n",
      "ğŸ“˜ Epoch 96: Loss = 0.1438\n",
      "ğŸ“˜ Epoch 97: Loss = 0.1416\n",
      "ğŸ“˜ Epoch 98: Loss = 0.1392\n",
      "ğŸ“˜ Epoch 99: Loss = 0.1380\n",
      "ğŸ“˜ Epoch 100: Loss = 0.1363\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LR = 3e-4\n",
    "MAX_LEN = 512\n",
    "\n",
    "# --- Dataset ---\n",
    "dataset = AgroDatasetTF(\n",
    "    \"dataset.jsonl\", \"tokenizer-agrolens.json\", max_len=MAX_LEN\n",
    ")\n",
    "dataset = dataset.padded_batch(\n",
    "    BATCH_SIZE, padded_shapes={\"input_ids\": [None], \"labels\": [None]}\n",
    ")\n",
    "dataset = dataset.shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# --- Model ---\n",
    "model = AgroLensGPT(vocab_size=8000)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction=\"none\"\n",
    ")\n",
    "\n",
    "display(model.summary())\n",
    "\n",
    "# --- Custom Training Loop ---\n",
    "@tf.function\n",
    "def train_step(input_ids, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(input_ids, training=True)\n",
    "        # Shifted label loss, ignoring padding (-100 equivalent in PyTorch)\n",
    "        mask = tf.cast(labels != -100, tf.float32)\n",
    "        loss_values = loss_fn(labels, logits)\n",
    "        loss = tf.reduce_sum(loss_values * mask) / tf.reduce_sum(mask)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss = train_step(input_ids, labels)\n",
    "        total_loss += loss.numpy()\n",
    "        steps += 1\n",
    "\n",
    "    avg_loss = total_loss / steps\n",
    "    print(f\"ğŸ“˜ Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "\n",
    "# --- Save weights ---\n",
    "model.save_weights(\"agrolens_model_tf.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28847bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# --- Konstanta dan Load Model ---\n",
    "MODEL_PATH = \"agrolens_model_tf.weights.h5\"\n",
    "TOKENIZER_PATH = \"tokenizer-agrolens.json\"\n",
    "VOCAB_SIZE = 8000\n",
    "MAX_LEN = 128\n",
    "\n",
    "model = AgroLensGPT(vocab_size=VOCAB_SIZE)\n",
    "dummy_input = tf.constant([[1] * 64], dtype=tf.int32)  # bentuk (1, 64)\n",
    "_ = model(dummy_input)  # memanggil forward p\n",
    "model.load_weights(MODEL_PATH)\n",
    "tokenizer = Tokenizer.from_file(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f88d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt: str, max_new_tokens=50):\n",
    "    # Tokenisasi prompt\n",
    "    input_ids = tokenizer.encode(prompt).ids\n",
    "    input_tensor = tf.constant([input_ids], dtype=tf.int32)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Loloskan input ke model\n",
    "        logits = model(input_tensor, training=False)\n",
    "\n",
    "        # Ambil token berikutnya dari distribusi logit terakhir\n",
    "        next_token = tf.argmax(logits[:, -1, :], axis=-1, output_type=tf.int32)\n",
    "\n",
    "        # Tambahkan ke input_tensor\n",
    "        input_tensor = tf.concat(\n",
    "            [input_tensor, tf.expand_dims(next_token, axis=1)], axis=1\n",
    "        )\n",
    "\n",
    "        # Jika token akhir ditemukan\n",
    "        if tokenizer.token_to_id(\"</s>\") in next_token.numpy():\n",
    "            break\n",
    "\n",
    "        # Batasi panjang maksimum\n",
    "        if input_tensor.shape[1] >= MAX_LEN:\n",
    "            break\n",
    "\n",
    "    # Decode output\n",
    "    output_ids = input_tensor[0].numpy().tolist()\n",
    "    return tokenizer.decode(output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53524a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e56fc2ad024449b0c9a9e1c13fa0a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='Apa itu penyakit blast?', description='â“ Pertanyaan:', layout=Layout(width='100%'),â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "input_box = widgets.Text(\n",
    "    value=\"Apa itu penyakit blast?\",\n",
    "    placeholder=\"Tulis pertanyaan di sini...\",\n",
    "    description=\"â“ Pertanyaan:\",\n",
    "    layout=widgets.Layout(width=\"100%\"),\n",
    ")\n",
    "\n",
    "output_box = widgets.Output()\n",
    "generate_button = widgets.Button(\n",
    "    description=\"Jawab ğŸš€\", button_style=\"success\", layout=widgets.Layout(width=\"15%\")\n",
    ")\n",
    "\n",
    "\n",
    "def on_generate_clicked(b):\n",
    "    prompt = input_box.value\n",
    "    response = generate(prompt)\n",
    "    output_box.clear_output()\n",
    "    with output_box:\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"### ğŸ§‘ Kamu: \\n{prompt}\\n---\\n### ğŸŒ¾ AgroLens Menjawab:\\n{response}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "generate_button.on_click(on_generate_clicked)\n",
    "\n",
    "# Tampilkan\n",
    "display(widgets.VBox([input_box, generate_button, output_box]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
