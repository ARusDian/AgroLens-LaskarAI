{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a99c492",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2fdc6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "✅ Tokenizer saved to tokenizer-agrolens.json\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer, models, pre_tokenizers, trainers, decoders\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "import json\n",
    "\n",
    "dataset_path = \"../../datasets/dataset.jsonl\"\n",
    "\n",
    "# === Load data ===\n",
    "with open(dataset_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = []\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        texts.append(data[\"prompt\"])\n",
    "        texts.append(data[\"response\"])\n",
    "\n",
    "# === Write to plain text (required by tokenizer trainer) ===\n",
    "with open(\"tokenizer_corpus.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for text in texts:\n",
    "        f.write(text.strip() + \"\\n\")\n",
    "\n",
    "# === Init tokenizer ===\n",
    "tokenizer = Tokenizer(models.BPE())\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=8000,\n",
    "    show_progress=True,\n",
    "    special_tokens=[\"<pad>\", \"<s>\", \"</s>\", \"<unk>\"],\n",
    ")\n",
    "\n",
    "# === Train ===\n",
    "tokenizer.train([\"tokenizer_corpus.txt\"], trainer)\n",
    "\n",
    "# === Post-processing untuk auto menambahkan <s> dan </s> saat encoding\n",
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"<s> $A </s>\",\n",
    "    pair=\"<s> $A </s> <s> $B </s>\",\n",
    "    special_tokens=[\n",
    "        (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "        (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    ],\n",
    ")\n",
    "\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "\n",
    "# === Save ===\n",
    "tokenizer.save(\"tokenizer-agrolens.json\")   \n",
    "print(\"✅ Tokenizer saved to tokenizer-agrolens.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d359a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'ĠApa', 'Ġitu', 'Ġpenyakit', 'Ġblast', '?', '</s>']\n",
      "[1, 176, 289, 128, 260, 21, 2]\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer-agrolens.json\")\n",
    "enc = tokenizer.encode(\"Apa itu penyakit blast?\")\n",
    "print(enc.tokens)\n",
    "print(enc.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecc0844",
   "metadata": {},
   "source": [
    "# GPTModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645b29c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:23:42.994916: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-05 01:23:43.148185: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749057823.202029    1032 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749057823.218871    1032 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749057823.335008    1032 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749057823.335040    1032 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749057823.335040    1032 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749057823.335041    1032 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-05 01:23:43.350338: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "class DecoderBlock(layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = layers.MultiHeadAttention(num_heads=n_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(d_model * 4, activation='relu'),\n",
    "            layers.Dense(d_model),\n",
    "        ])\n",
    "        self.norm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "\n",
    "    def call(self, x, training=False, mask=None):\n",
    "        attn = self.mha(x, x, attention_mask=mask, use_causal_mask=True)\n",
    "        attn = self.dropout1(attn, training=training)\n",
    "        x = self.norm1(x + attn)\n",
    "\n",
    "        ffn_out = self.ffn(x)\n",
    "        ffn_out = self.dropout2(ffn_out, training=training)\n",
    "        return self.norm2(x + ffn_out)\n",
    "\n",
    "\n",
    "class AgroLensGPT(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size,\n",
    "        max_length=512,\n",
    "        d_model=256,\n",
    "        n_heads=4,\n",
    "        n_layers=4,\n",
    "        dropout=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_length = max_length\n",
    "        self.token_embed = layers.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = layers.Embedding(max_length, d_model)\n",
    "        self.blocks = [DecoderBlock(d_model, n_heads, dropout) for _ in range(n_layers)]\n",
    "        self.final_norm = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.output_head = layers.Dense(vocab_size)\n",
    "\n",
    "        # Precomputed causal mask (for max_length)\n",
    "        self.causal_mask = tf.linalg.band_part(tf.ones((max_length, max_length)), -1, 0)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        B, T = tf.shape(x)[0], tf.shape(x)[1]\n",
    "        token_emb = self.token_embed(x)  # (B, T, d_model)\n",
    "        pos_indices = tf.range(start=0, limit=T)\n",
    "        pos_emb = self.pos_embed(pos_indices)[tf.newaxis, :, :]  # (1, T, d_model)\n",
    "\n",
    "        h = token_emb + pos_emb  # (B, T, d_model)\n",
    "        mask = self.causal_mask[:T, :T][tf.newaxis, tf.newaxis, :, :]  # (1, 1, T, T)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            h = block(h, training=training, mask=mask)\n",
    "\n",
    "        h = self.final_norm(h)\n",
    "        return self.output_head(h)  # (B, T, vocab_size)\n",
    "\n",
    "    def generate(self, tokenizer, prompt, max_new_tokens=50):\n",
    "        input_ids = tokenizer.encode(prompt).ids\n",
    "        input_tensor = tf.constant([input_ids], dtype=tf.int32)\n",
    "\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(input_tensor, training=False)\n",
    "            next_token = tf.argmax(logits[:, -1, :], axis=-1, output_type=tf.int32)\n",
    "            input_tensor = tf.concat(\n",
    "                [input_tensor, tf.expand_dims(next_token, axis=1)], axis=1\n",
    "            )\n",
    "\n",
    "            if next_token.numpy()[0] == tokenizer.token_to_id(\"</s>\"):\n",
    "                break\n",
    "            if input_tensor.shape[1] >= self.max_length:\n",
    "                break\n",
    "\n",
    "        return tokenizer.decode(input_tensor[0].numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fec44d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749057827.148919    1032 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"agro_lens_gpt\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"agro_lens_gpt\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_8           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block (\u001b[38;5;33mDecoderBlock\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_1 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_2 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_3 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_8           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 64, 8000)\n"
     ]
    }
   ],
   "source": [
    "model = AgroLensGPT(vocab_size=8000)\n",
    "display(model.summary())\n",
    "sample_input = tf.random.uniform((2, 64), minval=0, maxval=8000, dtype=tf.int32)\n",
    "logits = model(sample_input)\n",
    "print(logits.shape)  # Expected: (2, 64, 8000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ad101",
   "metadata": {},
   "source": [
    "# Loader dan Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d0427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "\n",
    "class AgroDatasetTF(tf.data.Dataset):\n",
    "    def __new__(cls, path, tokenizer_path, max_len=256):\n",
    "        tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "        samples = []\n",
    "\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                prompt = data[\"prompt\"]\n",
    "                response = data[\"response\"]\n",
    "                combined = f\"{prompt} {response}\"\n",
    "\n",
    "                # Tokenize and truncate\n",
    "                ids = tokenizer.encode(combined).ids[:max_len]\n",
    "\n",
    "                if len(ids) >= 2:  # minimal length to create input/label\n",
    "                    input_ids = ids[:-1]\n",
    "                    labels = ids[1:]\n",
    "                    samples.append((input_ids, labels))\n",
    "\n",
    "        # Convert to TensorFlow tensors\n",
    "        def gen():\n",
    "            for input_ids, labels in samples:\n",
    "                yield {\n",
    "                    \"input_ids\": tf.constant(input_ids, dtype=tf.int32),\n",
    "                    \"labels\": tf.constant(labels, dtype=tf.int32),\n",
    "                }\n",
    "\n",
    "        return tf.data.Dataset.from_generator(\n",
    "            gen,\n",
    "            output_signature={\n",
    "                \"input_ids\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "                \"labels\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe55cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 40) (8, 40)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:23:52.159261: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "dataset = AgroDatasetTF(\n",
    "    dataset_path, \"tokenizer-agrolens.json\", max_len=512\n",
    ")\n",
    "dataset = dataset.padded_batch(8, padded_shapes={\"input_ids\": [None], \"labels\": [None]})\n",
    "for batch in dataset.take(1):\n",
    "    print(batch[\"input_ids\"].shape, batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d8618d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"agro_lens_gpt_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"agro_lens_gpt_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DecoderBlock</span>)  │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_17          │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_4 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_5 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_6 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ decoder_block_7 (\u001b[38;5;33mDecoderBlock\u001b[0m)  │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer_normalization_17          │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function train_step at 0x7fa8a416cdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "📘 Epoch 1: Loss = 8.0781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:24:05.702623: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 2: Loss = 7.2472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:24:06.237593: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 3: Loss = 6.6469\n",
      "📘 Epoch 4: Loss = 6.0936\n",
      "📘 Epoch 5: Loss = 5.5957\n",
      "📘 Epoch 6: Loss = 5.1616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:24:07.212692: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 7: Loss = 4.8093\n",
      "📘 Epoch 8: Loss = 4.5174\n",
      "📘 Epoch 9: Loss = 4.2744\n",
      "📘 Epoch 10: Loss = 4.0653\n",
      "📘 Epoch 11: Loss = 3.8832\n",
      "📘 Epoch 12: Loss = 3.7086\n",
      "📘 Epoch 13: Loss = 3.5439\n",
      "📘 Epoch 14: Loss = 3.3860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:24:09.190210: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 15: Loss = 3.2355\n",
      "📘 Epoch 16: Loss = 3.0907\n",
      "📘 Epoch 17: Loss = 2.9482\n",
      "📘 Epoch 18: Loss = 2.8116\n",
      "📘 Epoch 19: Loss = 2.6923\n",
      "📘 Epoch 20: Loss = 2.5577\n",
      "📘 Epoch 21: Loss = 2.4333\n",
      "📘 Epoch 22: Loss = 2.3048\n",
      "📘 Epoch 23: Loss = 2.1950\n",
      "📘 Epoch 24: Loss = 2.0791\n",
      "📘 Epoch 25: Loss = 1.9714\n",
      "📘 Epoch 26: Loss = 1.8686\n",
      "📘 Epoch 27: Loss = 1.7505\n",
      "📘 Epoch 28: Loss = 1.6489\n",
      "📘 Epoch 29: Loss = 1.5559\n",
      "📘 Epoch 30: Loss = 1.4685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:24:12.980852: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 31: Loss = 1.3930\n",
      "📘 Epoch 32: Loss = 1.3079\n",
      "📘 Epoch 33: Loss = 1.2233\n",
      "📘 Epoch 34: Loss = 1.1397\n",
      "📘 Epoch 35: Loss = 1.0598\n",
      "📘 Epoch 36: Loss = 0.9861\n",
      "📘 Epoch 37: Loss = 0.9172\n",
      "📘 Epoch 38: Loss = 0.8484\n",
      "📘 Epoch 39: Loss = 0.7850\n",
      "📘 Epoch 40: Loss = 0.7252\n",
      "📘 Epoch 41: Loss = 0.6735\n",
      "📘 Epoch 42: Loss = 0.6303\n",
      "📘 Epoch 43: Loss = 0.5823\n",
      "📘 Epoch 44: Loss = 0.5425\n",
      "📘 Epoch 45: Loss = 0.5059\n",
      "📘 Epoch 46: Loss = 0.4744\n",
      "📘 Epoch 47: Loss = 0.4384\n",
      "📘 Epoch 48: Loss = 0.4124\n",
      "📘 Epoch 49: Loss = 0.3846\n",
      "📘 Epoch 50: Loss = 0.3601\n",
      "📘 Epoch 51: Loss = 0.3395\n",
      "📘 Epoch 52: Loss = 0.3203\n",
      "📘 Epoch 53: Loss = 0.3013\n",
      "📘 Epoch 54: Loss = 0.2841\n",
      "📘 Epoch 55: Loss = 0.2693\n",
      "📘 Epoch 56: Loss = 0.2583\n",
      "📘 Epoch 57: Loss = 0.2476\n",
      "📘 Epoch 58: Loss = 0.2366\n",
      "📘 Epoch 59: Loss = 0.2266\n",
      "📘 Epoch 60: Loss = 0.2163\n",
      "📘 Epoch 61: Loss = 0.2101\n",
      "📘 Epoch 62: Loss = 0.2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 01:24:20.822369: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📘 Epoch 63: Loss = 0.1941\n",
      "📘 Epoch 64: Loss = 0.1889\n",
      "📘 Epoch 65: Loss = 0.1835\n",
      "📘 Epoch 66: Loss = 0.1768\n",
      "📘 Epoch 67: Loss = 0.1708\n",
      "📘 Epoch 68: Loss = 0.1674\n",
      "📘 Epoch 69: Loss = 0.1630\n",
      "📘 Epoch 70: Loss = 0.1607\n",
      "📘 Epoch 71: Loss = 0.1571\n",
      "📘 Epoch 72: Loss = 0.1530\n",
      "📘 Epoch 73: Loss = 0.1496\n",
      "📘 Epoch 74: Loss = 0.1468\n",
      "📘 Epoch 75: Loss = 0.1437\n",
      "📘 Epoch 76: Loss = 0.1427\n",
      "📘 Epoch 77: Loss = 0.1397\n",
      "📘 Epoch 78: Loss = 0.1378\n",
      "📘 Epoch 79: Loss = 0.1352\n",
      "📘 Epoch 80: Loss = 0.1328\n",
      "📘 Epoch 81: Loss = 0.1324\n",
      "📘 Epoch 82: Loss = 0.1303\n",
      "📘 Epoch 83: Loss = 0.1288\n",
      "📘 Epoch 84: Loss = 0.1269\n",
      "📘 Epoch 85: Loss = 0.1247\n",
      "📘 Epoch 86: Loss = 0.1244\n",
      "📘 Epoch 87: Loss = 0.1240\n",
      "📘 Epoch 88: Loss = 0.1232\n",
      "📘 Epoch 89: Loss = 0.1191\n",
      "📘 Epoch 90: Loss = 0.1177\n",
      "📘 Epoch 91: Loss = 0.1171\n",
      "📘 Epoch 92: Loss = 0.1166\n",
      "📘 Epoch 93: Loss = 0.1154\n",
      "📘 Epoch 94: Loss = 0.1143\n",
      "📘 Epoch 95: Loss = 0.1141\n",
      "📘 Epoch 96: Loss = 0.1149\n",
      "📘 Epoch 97: Loss = 0.1138\n",
      "📘 Epoch 98: Loss = 0.1114\n",
      "📘 Epoch 99: Loss = 0.1114\n",
      "📘 Epoch 100: Loss = 0.1100\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LR = 3e-4\n",
    "MAX_LEN = 512\n",
    "\n",
    "# --- Dataset ---\n",
    "dataset = AgroDatasetTF(\n",
    "    dataset_path, \"tokenizer-agrolens.json\", max_len=MAX_LEN\n",
    ")\n",
    "dataset = dataset.padded_batch(\n",
    "    BATCH_SIZE, padded_shapes={\"input_ids\": [None], \"labels\": [None]}\n",
    ")\n",
    "dataset = dataset.shuffle(1000).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# --- Model ---\n",
    "model = AgroLensGPT(vocab_size=8000)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=LR)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction=\"none\"\n",
    ")\n",
    "\n",
    "display(model.summary())\n",
    "\n",
    "# --- Custom Training Loop ---\n",
    "@tf.function\n",
    "def train_step(input_ids, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(input_ids, training=True)\n",
    "        # Shifted label loss, ignoring padding (-100 equivalent in PyTorch)\n",
    "        mask = tf.cast(labels != -100, tf.float32)\n",
    "        loss_values = loss_fn(labels, logits)\n",
    "        loss = tf.reduce_sum(loss_values * mask) / tf.reduce_sum(mask)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "\n",
    "# --- Training Loop ---\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    steps = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        loss = train_step(input_ids, labels)\n",
    "        total_loss += loss.numpy()\n",
    "        steps += 1\n",
    "\n",
    "    avg_loss = total_loss / steps\n",
    "    print(f\"📘 Epoch {epoch+1}: Loss = {avg_loss:.4f}\")\n",
    "\n",
    "# --- Save weights ---\n",
    "model.save_weights(\"agrolens_model_tf.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28847bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "# --- Konstanta dan Load Model ---\n",
    "MODEL_PATH = \"agrolens_model_tf.weights.h5\"\n",
    "TOKENIZER_PATH = \"tokenizer-agrolens.json\"\n",
    "VOCAB_SIZE = 8000\n",
    "MAX_LEN = 128\n",
    "\n",
    "model = AgroLensGPT(vocab_size=VOCAB_SIZE)\n",
    "dummy_input = tf.constant([[1] * 64], dtype=tf.int32)  # bentuk (1, 64)\n",
    "_ = model(dummy_input)  # memanggil forward p\n",
    "model.load_weights(MODEL_PATH)\n",
    "tokenizer = Tokenizer.from_file(TOKENIZER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f88d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt: str, max_new_tokens=50):\n",
    "    # Tokenisasi prompt\n",
    "    input_ids = tokenizer.encode(prompt).ids\n",
    "    input_tensor = tf.constant([input_ids], dtype=tf.int32)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # Loloskan input ke model\n",
    "        logits = model(input_tensor, training=False)\n",
    "\n",
    "        # Ambil token berikutnya dari distribusi logit terakhir\n",
    "        next_token = tf.argmax(logits[:, -1, :], axis=-1, output_type=tf.int32)\n",
    "\n",
    "        # Tambahkan ke input_tensor\n",
    "        input_tensor = tf.concat(\n",
    "            [input_tensor, tf.expand_dims(next_token, axis=1)], axis=1\n",
    "        )\n",
    "\n",
    "        # Jika token akhir ditemukan\n",
    "        if tokenizer.token_to_id(\"</s>\") in next_token.numpy():\n",
    "            break\n",
    "\n",
    "        # Batasi panjang maksimum\n",
    "        if input_tensor.shape[1] >= MAX_LEN:\n",
    "            break\n",
    "\n",
    "    # Decode output\n",
    "    output_ids = input_tensor[0].numpy().tolist()\n",
    "    return tokenizer.decode(output_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53524a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4380111881a04e3f85a1b8abfc7e110a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='Apa itu penyakit blast?', description='❓ Pertanyaan:', layout=Layout(width='100%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "input_box = widgets.Text(\n",
    "    value=\"Apa itu penyakit blast?\",\n",
    "    placeholder=\"Tulis pertanyaan di sini...\",\n",
    "    description=\"❓ Pertanyaan:\",\n",
    "    layout=widgets.Layout(width=\"100%\"),\n",
    ")\n",
    "\n",
    "output_box = widgets.Output()\n",
    "generate_button = widgets.Button(\n",
    "    description=\"Jawab 🚀\", button_style=\"success\", layout=widgets.Layout(width=\"15%\")\n",
    ")\n",
    "\n",
    "\n",
    "def on_generate_clicked(b):\n",
    "    prompt = input_box.value\n",
    "    response = generate(prompt)\n",
    "    output_box.clear_output()\n",
    "    with output_box:\n",
    "        display(\n",
    "            Markdown(\n",
    "                f\"### 🧑 Kamu: \\n{prompt}\\n---\\n### 🌾 AgroLens Menjawab:\\n{response}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "generate_button.on_click(on_generate_clicked)\n",
    "\n",
    "# Tampilkan\n",
    "display(widgets.VBox([input_box, generate_button, output_box]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
