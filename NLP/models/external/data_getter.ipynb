{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c81381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load file Excel\n",
    "file_path = \"../../datasets/xlsx/Dataset Labeling Chatbot.xlsx\"\n",
    "blast_df = pd.read_excel(file_path, sheet_name=\"Blast\")\n",
    "tungro_df = pd.read_excel(file_path, sheet_name=\"Tungro\")\n",
    "bacterial_blight_df = pd.read_excel(file_path, sheet_name=\"BacterialBlight\")\n",
    "brown_spot_df = pd.read_excel(file_path, sheet_name=\"BrownSpot\")\n",
    "leaf_scald_df = pd.read_excel(file_path, sheet_name=\"LeafScald\")\n",
    "\n",
    "# Tambahkan kolom 'penyakit' untuk tiap dataframe\n",
    "blast_df[\"penyakit\"] = \"Blast\"\n",
    "tungro_df[\"penyakit\"] = \"Tungro\"\n",
    "bacterial_blight_df[\"penyakit\"] = \"Bacterial Blight\"\n",
    "brown_spot_df[\"penyakit\"] = \"Brown Spot\"\n",
    "leaf_scald_df[\"penyakit\"] = \"Leaf Scald\"\n",
    "\n",
    "# Gabungkan semua\n",
    "chatbot_df = pd.concat(\n",
    "    [blast_df, tungro_df, bacterial_blight_df, brown_spot_df, leaf_scald_df],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# Ambil kolom yang dibutuhkan\n",
    "chatbot_data = chatbot_df[[\"penyakit\", \"prompt\", \"response\"]].dropna()\n",
    "\n",
    "# Format ulang prompt dengan prefix <instruction>\n",
    "chatbot_data[\"prompt\"] = chatbot_data.apply(\n",
    "    lambda row: f\"<instruction>\\nPenyakit: {row['penyakit']}\\nPertanyaan: {row['prompt']}\\nJawaban:\",\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Simpan ke JSONL\n",
    "with open(\"chatbot_data_instruction.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in chatbot_data.iterrows():\n",
    "        json.dump(\n",
    "            {\"prompt\": row[\"prompt\"], \"response\": row[\"response\"]},\n",
    "            f,\n",
    "            ensure_ascii=False,\n",
    "        )\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab914dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# === Load file Excel ===\n",
    "file_path = \"../../datasets/xlsx/Dataset Labeling Chatbot.xlsx\"\n",
    "blast_df = pd.read_excel(file_path, sheet_name=\"Blast\")\n",
    "tungro_df = pd.read_excel(file_path, sheet_name=\"Tungro\")\n",
    "bacterial_blight_df = pd.read_excel(file_path, sheet_name=\"BacterialBlight\")\n",
    "brown_spot_df = pd.read_excel(file_path, sheet_name=\"BrownSpot\")\n",
    "leaf_scald_df = pd.read_excel(file_path, sheet_name=\"LeafScald\")\n",
    "\n",
    "# === Tambahkan label penyakit ===\n",
    "blast_df[\"penyakit\"] = \"Blast\"\n",
    "tungro_df[\"penyakit\"] = \"Tungro\"\n",
    "bacterial_blight_df[\"penyakit\"] = \"Bacterial Blight\"\n",
    "brown_spot_df[\"penyakit\"] = \"Brown Spot\"\n",
    "leaf_scald_df[\"penyakit\"] = \"Leaf Scald\"\n",
    "\n",
    "# === Gabungkan semua data ===\n",
    "chatbot_df = pd.concat(\n",
    "    [blast_df, tungro_df, bacterial_blight_df, brown_spot_df, leaf_scald_df],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "chatbot_df = chatbot_df[[\"penyakit\", \"prompt\"]].dropna()\n",
    "\n",
    "# === Template jawaban per penyakit ===\n",
    "template_responses = {\n",
    "    \"Blast\": (\n",
    "        \"Penyebab: Penyakit blast disebabkan oleh jamur Magnaporthe oryzae.\\n\"\n",
    "        \"Gejala: Bercak berbentuk belah ketupat berwarna cokelat keabu-abuan muncul di daun padi. \"\n",
    "        \"Pada serangan berat, bercak menyebar luas dan daun mengering.\\n\"\n",
    "        \"Dampak: Infeksi berat dapat menurunkan hasil panen hingga 70%.\"\n",
    "    ),\n",
    "    \"Tungro\": (\n",
    "        \"Penyebab: Penyakit tungro disebabkan oleh kombinasi dua virus, RTSV dan RTBV, yang ditularkan melalui wereng hijau.\\n\"\n",
    "        \"Gejala: Daun menguning, kaku, dan pertumbuhan tanaman terhambat. Daun bisa menggulung ke bawah.\\n\"\n",
    "        \"Dampak: Kehilangan hasil panen bisa mencapai 100% jika infeksi terjadi pada fase awal.\"\n",
    "    ),\n",
    "    \"Bacterial Blight\": (\n",
    "        \"Penyebab: Penyakit ini disebabkan oleh bakteri Xanthomonas oryzae pv. oryzae.\\n\"\n",
    "        \"Gejala: Daun menunjukkan bercak putih kekuningan yang memanjang dari tepi daun. Daun bisa layu dan mati.\\n\"\n",
    "        \"Dampak: Penurunan hasil panen hingga 60% pada kasus berat.\"\n",
    "    ),\n",
    "    \"Brown Spot\": (\n",
    "        \"Penyebab: Penyakit ini disebabkan oleh jamur Bipolaris oryzae.\\n\"\n",
    "        \"Gejala: Muncul bercak bulat berwarna cokelat gelap dengan tepi cokelat kemerahan pada daun.\\n\"\n",
    "        \"Dampak: Dapat menurunkan kualitas dan kuantitas gabah jika tidak dikendalikan.\"\n",
    "    ),\n",
    "    \"Leaf Scald\": (\n",
    "        \"Penyebab: Penyakit leaf scald disebabkan oleh jamur Microdochium oryzae.\\n\"\n",
    "        \"Gejala: Daun menunjukkan bercak cokelat tua yang berkembang dari ujung dan tepi daun, menyerupai bekas luka.\\n\"\n",
    "        \"Dampak: Infeksi berat bisa menyebabkan daun mati dan menurunkan hasil panen.\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "# === Format dan simpan ulang ===\n",
    "output_path = \"chatbot_data_cleaned.jsonl\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in chatbot_df.iterrows():\n",
    "        formatted_prompt = f\"<instruction>\\nPenyakit: {row['penyakit']}\\nPertanyaan: {row['prompt']}\\nJawaban:\"\n",
    "        response = template_responses[row[\"penyakit\"]]\n",
    "        json.dump(\n",
    "            {\"prompt\": formatted_prompt, \"response\": response}, f, ensure_ascii=False\n",
    "        )\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c3c0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siapkan data untuk RAG\n",
    "rag_data = []\n",
    "\n",
    "for _, row in chatbot_df.iterrows():\n",
    "    if pd.notnull(row[\"response\"]):\n",
    "        doc = {\n",
    "            \"text\": row[\"response\"],\n",
    "            \"metadata\": {\n",
    "                \"penyakit\": row.get(\"Penyakit\", \"Unknown\"),\n",
    "                \"topik\": row.get(\"topik\", \"Unknown\"),\n",
    "                \"sumber\": row.get(\"sumber\", \"\"),\n",
    "            },\n",
    "        }\n",
    "        rag_data.append(doc)\n",
    "\n",
    "# Simpan dalam format JSONL\n",
    "with open(\"rag_documents.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in rag_data:\n",
    "        json.dump(item, f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53e2732b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 02:13:17.099050: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-13 02:13:17.109526: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749751997.123688   10043 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749751997.128056   10043 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749751997.137927   10043 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749751997.137945   10043 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749751997.137946   10043 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749751997.137947   10043 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-13 02:13:17.141541: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b20de16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruvne/anaconda3/envs/py310/lib/python3.10/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_10043/3809624487.py:42: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='282' max='282' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [282/282 04:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.775600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>2.604700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>2.619700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.451300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>2.345000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>2.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.489200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.382100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.219300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>2.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>2.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>2.266100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.281100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.244900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.250900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>2.196500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>2.141100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>2.200700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.127800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>2.066400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>2.191900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>2.170400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>2.141600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>2.083800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>2.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>2.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>2.035800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=282, training_loss=2.2950226237587894, metrics={'train_runtime': 263.899, 'train_samples_per_second': 4.263, 'train_steps_per_second': 1.069, 'total_flos': 261197070336000.0, 'train_loss': 2.2950226237587894, 'epoch': 3.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load dataset JSONL\n",
    "dataset = load_dataset(\"json\", data_files=\"chatbot_data_reformat.jsonl\", split=\"train\")\n",
    "\n",
    "# Gabungkan prompt dan response jadi satu kolom 'text' untuk training\n",
    "dataset = dataset.map(lambda x: {\"text\": f\"{x['prompt']} {x['response']}\"})\n",
    "\n",
    "# Load model & tokenizer\n",
    "model_name = \"cahya/indochat-tiny\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Tambah pad token jika belum ada\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "\n",
    "# Tokenisasi\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"], truncation=True, padding=\"max_length\", max_length=128\n",
    "    )\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./indochat-chatbot\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    report_to=\"none\",\n",
    "    overwrite_output_dir=True,\n",
    ")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a520a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('indochat-chatbot-finetuned/tokenizer_config.json',\n",
       " 'indochat-chatbot-finetuned/special_tokens_map.json',\n",
       " 'indochat-chatbot-finetuned/vocab.json',\n",
       " 'indochat-chatbot-finetuned/merges.txt',\n",
       " 'indochat-chatbot-finetuned/added_tokens.json',\n",
       " 'indochat-chatbot-finetuned/tokenizer.json')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"indochat-chatbot-finetuned\")\n",
    "tokenizer.save_pretrained(\"indochat-chatbot-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba73b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': '<instruction>Penyakit: Blast\\nPertanyaan: Apa penyebabnya?.\\nJawaban: Penyakit blast disebabkan oleh jamur yang disebut Chlamydia pulchella. Jamur ini menghasilkan spora dan dapat menginfeksi tanaman padi atau gulma lain, serta menyebabkan kerusakan pada benih akibat pelepasan glikosida ke dalam air nutrisi saat proses fotosintesis berlangsung. Spora kemudian bergerak melalui udara (airborne) untuk menyebarkan penyakit dari satu titik infeksi menuju jaringan sehat lainnya di seluruh area tanam sehingga merusak hasil panen secara signifikan hingga menjadi gagal tumbuh total tanpa gejala'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indochat-chatbot-finetuned\")\n",
    "chatbot = pipeline(\n",
    "    \"text-generation\", model=\"indochat-chatbot-finetuned\", tokenizer=tokenizer\n",
    ")\n",
    "chatbot(\n",
    "    \"<instruction>Penyakit: Blast\\nPertanyaan: Apa penyebabnya?.\\nJawaban:\",\n",
    "    max_new_tokens=85,\n",
    "    temperature=0.5,\n",
    "    top_p=0.85,\n",
    "    repetition_penalty=1.4,\n",
    "    no_repeat_ngram_size=5,\n",
    "    do_sample=True,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
